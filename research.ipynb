{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING LIBRARIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (6.29.5)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipykernel) (0.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipykernel) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipykernel) (8.12.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipykernel) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipykernel) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipykernel) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipykernel) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipykernel) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipykernel) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: backcall in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.19.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.4.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (7.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (305.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel) (3.17.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.23.1->ipykernel) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: executing in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n",
      "Requirement already satisfied: ctransformers in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (0.2.5)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from ctransformers) (0.25.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub->ctransformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub->ctransformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub->ctransformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub->ctransformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub->ctransformers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub->ctransformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub->ctransformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->ctransformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from requests->huggingface-hub->ctransformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from requests->huggingface-hub->ctransformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from requests->huggingface-hub->ctransformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from requests->huggingface-hub->ctransformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "# calling all the libraries \n",
    "!pip install ipykernel\n",
    "!pip install ctransformers\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import retrieval_qa \n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.vectorstores import pinecone\n",
    "#import pinecone\n",
    "from langchain.document_loaders import PyMuPDFLoader, DirectoryLoader, PyPDFLoader\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PINECONE_API_KEY = \"d43c6d43-4465-4079-a3b6-a3cfc22bc808\"\n",
    "PINECONE_API_ENV = \"us-east-1\"\n",
    "os.environ['PINECONE_API_KEY'] = \"d43c6d43-4465-4079-a3b6-a3cfc22bc808\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extrating data from pdf\n",
    "\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(\n",
    "        data,\n",
    "        glob=\"*.pdf\",\n",
    "        loader_cls=PyPDFLoader\n",
    "    )\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracter_data = load_pdf(r\"C:\\Users\\harshita\\proj2\\data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHUNKS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting corpus into chunks \n",
    "def text_split(extracter_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500 , \n",
    "                                   chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracter_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Chunks 7020\n"
     ]
    }
   ],
   "source": [
    "text_chunks=text_split(extracter_data)\n",
    "print(\"Length of Text Chunks\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HUGGING FACE \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector embedding model\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "    )\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harshita\\AppData\\Local\\Temp\\ipykernel_15272\\3523299516.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "c:\\Users\\harshita\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "query_results = embeddings.embed_query(\"Hello world\")\n",
    "print(len(query_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for all text chunks\n",
    "texts = [chunk.page_content for chunk in text_chunks]\n",
    "embeddings_list = embeddings.embed_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "#Prepare vectors for upsert\n",
    "vectors = []\n",
    "for i, (embedding, chunk) in enumerate(zip(embeddings_list, text_chunks)):\n",
    "    vector_id = f\"chunk-{i}-{uuid.uuid4()}\"  # Unique ID\n",
    "    metadata = {\n",
    "        \"text\": chunk.page_content, \n",
    "        #\"source\": chunk.metadata.get(\"source\", \"unknown\"),\n",
    "        #\"page\": chunk.metadata.get(\"page\", \"unknown\"),\n",
    "        # Add more metadata fields as needed\n",
    "    }\n",
    "    vectors.append((vector_id, embedding, metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PINECONE INTEGRATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=os.environ.get('d43c6d43-4465-4079-a3b6-a3cfc22bc808')\n",
    "#OPENAI_API_KEY=os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to create a new index\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"medicalbot\"\n",
    "\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384, \n",
    "    metric=\"cosine\", \n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\", \n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#already created index\n",
    "#to create a new index\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"medicalbot\"\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a batch upsert function\n",
    "def batch_upsert(index, vectors, batch_size=500):\n",
    "    \"\"\"\n",
    "    Upsert vectors into Pinecone index in batches.\n",
    "\n",
    "    :param index: Pinecone Index object\n",
    "    :param vectors: List of tuples (id, vector, metadata)\n",
    "    :param batch_size: Number of vectors per batch\n",
    "    \"\"\"\n",
    "    total_vectors = len(vectors)\n",
    "    for i in range(0, total_vectors, batch_size):\n",
    "        batch = vectors[i:i + batch_size]\n",
    "        try:\n",
    "            upsert_response = index.upsert(vectors=batch)\n",
    "            print(f\"Upserted batch {i // batch_size + 1} ({len(batch)} vectors).\")\n",
    "        except pinecone.core.client.exceptions.PineconeException as e:\n",
    "            print(f\"Error upserting batch {i // batch_size + 1}: {e}\")\n",
    "\n",
    "# Performing batched upsert\n",
    "batch_size = 500  \n",
    "batch_upsert(index, vectors, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic search function\n",
    "def semantic_search(query, top_k=3):\n",
    "    # Generate embedding for the query\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    \n",
    "    # Query the Pinecone index\n",
    "    search_results = index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    \n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example usage of semantic search\n",
    "if __name__ == \"__main__\":\n",
    "    # Get user input for the search query\n",
    "    user_query = input(\"Enter your Question \")\n",
    "    \n",
    "    # Perform semantic search\n",
    "    results = semantic_search(user_query, top_k=3)\n",
    "    \n",
    "\n",
    "# Display the results\n",
    "print(results.matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Use the following peices of interaction to answer the users question.\n",
    "If you dont know the abswer , just say u dont know, dont make up your own answers.\n",
    "\n",
    "context : {context}\n",
    "question : {question}\n",
    "\n",
    "only return the helpful answer below\n",
    "\n",
    "helpful answer: \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompt = PromptTemplate(\n",
    "    input_variables=[\"context\",\"question\"],\n",
    "    template = prompt_template\n",
    ")\n",
    "\n",
    "chain_type = {\"prompt\" : Prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CTransformers(model = \"MODEL/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                    model_type=\"llama\",\n",
    "                    config={'max_new_tokens':512,\n",
    "                            'temperature':0.8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VECTOR SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "docsearch = Pinecone.from_documents(\n",
    "    documents = text_chunks,\n",
    "    index_name = index_name,\n",
    "    embedding =embeddings \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.pinecone.Pinecone at 0x26c1a560850>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINING RETRIEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(\n",
    "    search_type = \"similarity\",\n",
    "    search_kwargs = {\"k\":3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_docs = retriever.invoke(\"What is Acne?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 37.0, 'source': 'C:\\\\Users\\\\harshita\\\\proj2\\\\data\\\\Medical_book.pdf'}, page_content='Acidosis seeRespiratory acidosis; Renal\\ntubular acidosis; Metabolic acidosis\\nAcne\\nDefinition\\nAcne is a common skin disease characterized by\\npimples on the face, chest, and back. It occurs when thepores of the skin become clogged with oil, dead skincells, and bacteria.\\nDescription\\nAcne vulgaris, the medical term for common acne, is'),\n",
       " Document(metadata={'page': 38.0, 'source': 'C:\\\\Users\\\\harshita\\\\proj2\\\\data\\\\Medical_book.pdf'}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 2 25Acne\\nAcne vulgaris affecting a womanâ€™s face. Acne is the general\\nname given to a skin disorder in which the sebaceousglands become inflamed. (Photograph by Biophoto Associ-\\nates, Photo Researchers, Inc. Reproduced by permission.)GEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 25'),\n",
       " Document(metadata={'page': 239.0, 'source': 'C:\\\\Users\\\\harshita\\\\proj2\\\\data\\\\Medical_book.pdf'}, page_content='ent purposes. For example, lotions, soaps, gels, andcreams containing benzoyl peroxide or tretinoin may beused to clear up mild to moderately severe acne.Isotretinoin (Accutane) is prescribed only for verysevere, disfiguring acne.\\nAcne is a skin condition that occurs when pores or')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\",\n",
    "    retriever = docsearch.as_retriever(search_kwargs = {'k':2}),\n",
    "    return_source_documents = True,\n",
    "    #chain_type_kwargs = chain_type_kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response :   Acne is a common skin disease characterized by pimples on the face, chest, and back. It occurs when the pores of the skin become clogged with oil, dead skin cells, and bacteria.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(f\"Input Prompt\")\n",
    "    result = qa({\"query\":user_input})\n",
    "    print(\"Response : \", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
